<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Bayesian Multinomial Logit Model with HART Prior — rhierMnlRwMixture • bayesm.HART</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Bayesian Multinomial Logit Model with HART Prior — rhierMnlRwMixture"><meta name="description" content="rhierMnlRwMixture implements a MCMC algorithm for a Bayesian multinomial
logit model with a Hierarchical Additive Regression Trees (HART) prior. The model
allows for flexible modeling of the representative consumer and captures
unobserved preference heterogeneity."><meta property="og:description" content="rhierMnlRwMixture implements a MCMC algorithm for a Bayesian multinomial
logit model with a Hierarchical Additive Regression Trees (HART) prior. The model
allows for flexible modeling of the representative consumer and captures
unobserved preference heterogeneity."><!-- Copyright (c) 2000-2023 etracker GmbH. All rights reserved. --><!-- This material may not be reproduced, displayed, modified or distributed --><!-- without the express prior written permission of the copyright holder. --><!-- etracker tracklet 5.0 --><script type="text/javascript">
// var et_pagename = "";
// var et_areas = "";
// var et_tval = 0;
// var et_tsale = 0;
// var et_tonr = "";
// var et_basket = "";
</script><script id="_etLoader" type="text/javascript" charset="UTF-8" data-block-cookies="true" data-secure-code="6ggnmg" src="//code.etracker.com/code/e.js" async></script><!-- etracker tracklet 5.0 end --><!-- math rendering issues  https://github.com/r-lib/pkgdown/issues/2704 --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">bayesm.HART</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/getstarted.html">Get Started</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Bayesian Multinomial Logit Model with HART Prior</h1>

      <div class="d-none name"><code>rhierMnlRwMixture.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p><code>rhierMnlRwMixture</code> implements a MCMC algorithm for a Bayesian multinomial
logit model with a Hierarchical Additive Regression Trees (HART) prior. The model
allows for flexible modeling of the representative consumer and captures
unobserved preference heterogeneity.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">rhierMnlRwMixture</span><span class="op">(</span><span class="va">Data</span>, <span class="va">Prior</span>, <span class="va">Mcmc</span>, r_verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-data">Data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>A list containing:</p><ul><li><p><code>p</code>: Number of choice alternatives (integer).</p></li>
<li><p><code>lgtdata</code>: A list of length <code>nlgt</code>. Each element <code>lgtdata[[i]]</code> must be a list with:</p><ul><li><p><code>y</code>: <code>n_i x 1</code> vector of multinomial outcomes (1 to <code>p</code>).</p></li>
<li><p><code>X</code>: <code>(n_i * p) x nvar</code> matrix of alternative-specific attributes.</p></li>
</ul></li>
<li><p><code>Z</code> (optional): <code>nlgt x nz</code> matrix of observed characteristics for each unit.
<strong>Should NOT contain an intercept</strong> and is typically centered.</p></li>
</ul></dd>


<dt id="arg-prior">Prior<a class="anchor" aria-label="anchor" href="#arg-prior"></a></dt>
<dd><p>A list containing prior parameters:</p><ul><li><p><code>ncomp</code>: Number of mixture components (required).</p></li>
<li><p><code>a</code> (optional): <code>ncomp x 1</code> vector of Dirichlet prior parameters for mixture weights <code>pvec</code> (default: <code>rep(5, ncomp)</code>).</p></li>
<li><p><code>deltabar</code> (optional): <code>nz * nvar x 1</code> prior mean for <code>vec(Delta)</code> (default: 0). Ignored if BART is used.</p></li>
<li><p><code>Ad</code> (optional): Prior precision matrix for <code>vec(Delta)</code> (default: <code>0.01 * I</code>). Ignored if BART is used.</p></li>
<li><p><code>mubar</code> (optional): <code>nvar x 1</code> prior mean for component means (default: 0 if unrestricted, 2 if restricted).</p></li>
<li><p><code>Amu</code> (optional): Prior precision for component means (default: 0.01 if unrestricted, 0.1 if restricted).</p></li>
<li><p><code>nu</code> (optional): Degrees of freedom for IW prior on component <code>Sigma</code> (default: <code>nvar+3</code> if unrestricted, <code>nvar+15</code> if restricted).</p></li>
<li><p><code>V</code> (optional): Location matrix for IW prior on component <code>Sigma</code> (default: <code>nu * I</code> or scaled based on restriction).</p></li>
<li><p><code>SignRes</code> (optional): <code>nvar x 1</code> vector of sign restrictions (0=none, 1=pos, -1=neg). Default: <code>rep(0, nvar)</code>.</p></li>
<li><p><code>bart</code> (optional): List of parameters for the HART prior. If specified, this models the representative consumer \(\Delta(Z)\) as a sum-of-trees. See Details.</p></li>
</ul></dd>


<dt id="arg-mcmc">Mcmc<a class="anchor" aria-label="anchor" href="#arg-mcmc"></a></dt>
<dd><p>A list containing MCMC parameters:</p><ul><li><p><code>R</code>: Number of MCMC iterations (required).</p></li>
<li><p><code>keep</code> (optional): Thinning parameter (default: 1).</p></li>
<li><p><code>nprint</code> (optional): Print progress every <code>nprint</code> draws (default: 100, 0 for none).</p></li>
<li><p><code>s</code> (optional): RW Metropolis scaling parameter (default: <code>2.93 / sqrt(nvar)</code>).</p></li>
<li><p><code>w</code> (optional): Fractional likelihood weighting parameter (default: 0.1).</p></li>
</ul></dd>


<dt id="arg-r-verbose">r_verbose<a class="anchor" aria-label="anchor" href="#arg-r-verbose"></a></dt>
<dd><p>Logical. Print startup messages? Default TRUE.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A list containing:</p><ul><li><p><code>Deltadraw</code>: If <code>Z</code> provided and <code>bart=NULL</code>, <code>(R/keep) x (nz * nvar)</code> matrix of <code>vec(Delta)</code> draws.</p></li>
<li><p><code>betadraw</code>: <code>nlgt x nvar x (R/keep)</code> array of unit-level <code>beta_i</code> draws.</p></li>
<li><p><code>nmix</code>: List containing mixture draws (<code>probdraw</code>, <code>zdraw</code>, <code>compdraw</code>). See Details.</p></li>
<li><p><code>loglike</code>: <code>(R/keep) x 1</code> vector of log-likelihood values at kept draws.</p></li>
<li><p><code>SignRes</code>: <code>nvar x 1</code> vector of sign restrictions used.</p></li>
<li><p><code>bart_trees</code>: If BART used, list containing tree structures.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>

<div class="section">
<h3 id="model-and-priors">Model and Priors<a class="anchor" aria-label="anchor" href="#model-and-priors"></a></h3>


<p>\(y_i \sim MNL(X_i, \beta_i)\) for unit \(i = 1, ..., nlgt\).
The unit-level coefficients (part-worths) \(\beta_i\) are modeled as:
$$\beta_i = \Delta(Z_i) + u_i$$
where \(\Delta(Z_i)\) is the <em>representative consumer</em> component, which depends on observed characteristics \(Z_i\), and \(u_i\) is the unobserved heterogeneity component.</p><ul><li><p>If <code>Z</code> is provided and <code>Prior$bart</code> is <code>NULL</code>: \(\Delta(Z_i) = Z_i \Delta\) (linear model).</p></li>
<li><p>If <code>Z</code> is provided and <code>Prior$bart</code> is a list: \(\Delta(Z_i)\) is modeled with a HART prior (sum-of-trees).</p></li>
<li><p>If <code>Z</code> is <code>NULL</code>: \(\Delta(Z_i) = 0\).</p></li>
</ul><p>The unobserved heterogeneity component \(u_i\) follows a mixture of normals:
$$u_i \sim \sum_{j=1}^{ncomp} p_j N(\mu_j, \Sigma_j)$$</p>
<p><strong>Priors:</strong></p><ul><li><p>For mixture weights: \(pvec \sim Dirichlet(a)\)</p></li>
<li><p>For the linear model: \(\delta = vec(\Delta) \sim N(deltabar, A_d^{-1})\)</p></li>
<li><p>For the HART model: A sum-of-trees prior is placed on each dimension of a standardized \(\Delta(Z_i)\). See BART details below.</p></li>
<li><p>For mixture component means: \(\mu_j \sim N(mubar, \Sigma_j \otimes Amu^{-1})\) (Note: Scaled by Sigma_j)</p></li>
<li><p>For mixture component covariance: \(\Sigma_j \sim IW(\nu, V)\)</p></li>
</ul></div>

<div class="section">
<h3 id="argument-details">Argument Details<a class="anchor" aria-label="anchor" href="#argument-details"></a></h3>


<p><strong>Data List:</strong></p><ul><li><p><code>p</code>: Number of alternatives.</p></li>
<li><p><code>lgtdata</code>: List of <code>nlgt</code> lists. <code>lgtdata[[i]] = list(y, X)</code>.</p></li>
<li><p><code>Z</code>: <code>nlgt x nz</code> matrix (optional). Centered, no intercept.</p></li>
</ul><p><strong>Prior List:</strong></p><ul><li><p><code>ncomp</code>: Number of mixture components.</p></li>
<li><p>See <code>@param</code> descriptions for defaults.</p></li>
</ul><p><strong>Mcmc List:</strong></p><ul><li><p><code>R</code>: Number of draws.</p></li>
<li><p>See <code>@param</code> descriptions for defaults.</p></li>
</ul><p><strong>HART Prior (<code>Prior$bart</code>):</strong>
If <code>Prior$bart</code> is a list, it specifies a HART prior for the representative consumer, \(\Delta(Z)\).
This replaces the conventional linear specification \(Z \Delta\). The HART prior models each dimension of
the (standardized) representative consumer as a sum-of-trees.
Relevant parameters (defaults used if not specified in <code>Prior$bart</code>):</p><ul><li><p><code>num_trees</code>: Number of trees in each sum-of-trees model (default: 200).</p></li>
<li><p><code>power</code>, <code>base</code>: Parameters for the tree structure prior. The probability of a node at depth <code>q</code> splitting is \(\alpha(1+q)^{-\beta}\), where <code>base</code>=<code>\alpha</code> and <code>power</code>=<code>\beta</code>. Defaults are <code>base=0.95</code>, <code>power=2</code>, which favors shallow trees.</p></li>
<li><p><code>tau</code>: The standard deviation for the normal prior on terminal leaf coefficients, \(\lambda_{dhg} \sim N(0, \tau^2)\). The default value is <code>1/sqrt(num_trees)</code>, which regularizes the model by shrinking individual tree contributions to be small.</p></li>
<li><p><code>numcut</code>: Number of grid points for proposing splitting rules for continuous variables (default: 100).</p></li>
<li><p><code>sparse</code>: If <code>TRUE</code>, use the Dirichlet HART prior to induce sparsity. See next section. (default: <code>FALSE</code>).</p></li>
<li><p><code>burn</code>: Number of internal burn-in iterations for the BART-sampler within each MCMC iteration (default: 100).</p></li>
</ul></div>

<div class="section">
<h3 id="dirichlet-hart-sparse-true-">Dirichlet HART (<code>sparse = TRUE</code>)<a class="anchor" aria-label="anchor" href="#dirichlet-hart-sparse-true-"></a></h3>


<p>The Dirichlet HART model augments the HART prior to induce sparsity in variable selection, following Linero (2018). The selection probabilities for splitting variables are given a <code>Dirichlet(zeta/K, ..., zeta/K)</code> prior, where <code>K</code> is the number of characteristics. The concentration parameter <code>zeta</code> is given a <code>Beta(a,b)</code> hyperprior on <code>zeta/(zeta+rho)</code>.</p><ul><li><p><code>a</code>, <code>b</code>: Shape parameters for the Beta hyperprior. The default (<code>a=0.5, b=1</code>) induces sparsity.</p></li>
<li><p><code>rho</code>: A parameter that influences the number of selected variables. Default is the number of characteristics.</p></li>
<li><p><code>theta</code>, <code>omega</code>: Additional parameters for the sparsity-inducing prior (defaults: 0.0, 1.0).</p></li>
<li><p><code>aug</code>: Logical. For internal use, not relevant for the logit model.</p></li>
</ul></div>

<div class="section">
<h3 id="sign-restrictions">Sign Restrictions<a class="anchor" aria-label="anchor" href="#sign-restrictions"></a></h3>


<p>If <code>SignRes[k]</code> is non-zero, the k-th coefficient \(\beta_{ik}\) is modeled as
$$\beta_{ik} = SignRes[k] \cdot exp(\beta^*_{ik}).$$
The <code>betadraw</code> output contains the draws for \(\beta_{ik}\) (with the restriction applied).
The <code>nmix</code> output contains draws for the <em>unrestricted</em> mixture components.</p>
</div>

<div class="section">
<h3 id="nmix-details"><code>nmix</code> Details<a class="anchor" aria-label="anchor" href="#nmix-details"></a></h3>


<p><code>nmix</code> is a list: <code>list(probdraw, zdraw, compdraw)</code></p><ul><li><p><code>probdraw</code>: <code>(R/keep) x ncomp</code> matrix of mixture component probabilities.</p></li>
<li><p><code>zdraw</code>: <code>(R/keep) x nlgt</code> matrix of component <em>assignments</em> for each unit (i.e., which <code>j</code> for \(u_i\)).</p></li>
<li><p><code>compdraw</code>: <code>(R/keep)</code> list of <code>ncomp</code> lists. <code>compdraw[[r]][[j]] = list(mu, rooti)</code> contains the draw of \(\mu_j\) and \(\Sigma_j^{-1/2}\) for component <code>j</code> at kept draw <code>r</code>.</p></li>
</ul></div>

    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Rossi, Peter E., Greg M. Allenby, and Robert McCulloch (2009). Bayesian Statistics and Marketing. Reprint. Wiley Series in Probability and Statistics. Chichester: Wiley.</p>
<p>Rossi, Peter (2023). bayesm: Bayesian Inference for Marketing/Micro-Econometrics. Comprehensive R Archive Network.</p>
<p>Wiemann, Thomas (2025). "Personalization with HART." Working paper.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code>rmnlIndepMetrop</code></p>
<p><code><a href="predict.rhierMnlRwMixture.html">predict.rhierMnlRwMixture()</a></code></p></div>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Peter Rossi (original bayesm code), Thomas Wiemann (HART modifications).</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Thomas Wiemann.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

