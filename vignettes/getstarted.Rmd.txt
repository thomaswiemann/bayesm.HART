---
title: "Get Started"
date: "2025-06-29"
output: rmarkdown::html_vignette
vignette: |
  %\VignetteIndexEntry{Get Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "figures/",
  eval = TRUE
)
```

## Introduction
  
This vignette illustrates how to use the `bayesm.HART` package to estimate a hierarchical multinomial logit model. We replicate the application to the `bank` conjoint dataset from `bayesm`, which was originally analyzed by Allenby and Ginter (1995).

The key feature of the `bayesm.HART` package is the use of a Hierarchical Additive Regression Tree (HART) prior. This allows for a flexible, non-parametric specification of the *representative consumer* as a function of observed characteristics. We contrast the HART logit model with a conventional hierarchical logit model that specifies the representative consumer as a linear function of characteristics.

## Load dependencies and data

We first load the necessary packages and the `bank` dataset. 
```{r setup}
# library(devtools)
# load_all()
library(bayesm)
library(bayesm.HART)
library(ggplot2)
library(tidyr)
library(dplyr)
```

We then re-format the data for use with `rhierMnlRwMixture`. The `y` variable contains the binary choices, and `X` is the design matrix of credit card attributes. `Z` contains the centered respondent characteristics (age, income, gender).

```{r data-prep}
data(bank)

choiceAtt <- bank$choiceAtt
hh <- levels(factor(choiceAtt$id))
nhh <- length(hh)

lgtdata <- vector("list", length = nhh)
for (i in 1:nhh) {
    y = 2 - choiceAtt[choiceAtt[,1]==hh[i], 2]
    nobs = length(y)
    X_temp = as.matrix(choiceAtt[choiceAtt[,1]==hh[i], c(3:16)])
    X = matrix(0, nrow = nrow(X_temp) * 2, ncol = ncol(X_temp))
    X[seq(1, nrow(X), by = 2), ] = X_temp
    lgtdata[[i]] = list(y=y, X=X)
}

Z <- as.matrix(bank$demo[, -1])
Z_means <- colMeans(Z)
Z <- t(t(Z) - Z_means)

Data <- list(lgtdata = lgtdata, Z = Z, p = 2)
```

## Estimate Models

We fit two models: the HART logit model and a conventional linear hierarchical logit model. The only difference between the two is the specification of the representative consumer, $\Delta(Z)$. The HART model uses a sum-of-trees prior, while the linear model uses a linear function of `Z`.

```{r fit-models, cache=TRUE, message=FALSE, warning=FALSE}
# MCMC parameters
R <- 2500
burn <- 250
keep <- 1
Mcmc <- list(R = R, keep = keep)

out_hart <- bayesm.HART::rhierMnlRwMixture(
  Data = Data, Mcmc = Mcmc, 
  Prior = list(ncomp = 1, bart = list(num_trees = 20))
)

out_lin <- bayesm::rhierMnlRwMixture(
  Data = Data, Mcmc = Mcmc,
  Prior = list(ncomp = 1)
)
class(out_lin) <- "rhierMnlRwMixture"

```

## MCMC Diagnostics

A simple way to check for convergence is to plot the log-likelihood over MCMC iterations. We expect the plot to show a stable path around a mean value after the burn-in period.

```{r mcmc-diagnostics,  fig.width=8,fig.height=5, fig.align='center', out.width="90%", dpi = 200, fig.cap="MCMC Traceplot of the Log Likelihood."}
burnin_draws <- ceiling(burn / keep) 

mcmc_data <- data.frame(
  Iteration = (1:length(out_hart$loglike)) * keep,
  HART = out_hart$loglike,
  Linear = out_lin$loglike
) %>% 
  pivot_longer(cols = c("HART", "Linear"), names_to = "Model", values_to = "LogLikelihood")

ggplot(mcmc_data, aes(x = Iteration, y = LogLikelihood, color = Model)) +
  geom_line(alpha = 0.8) +
  geom_vline(xintercept = burn, linetype = "dashed", color = "black") +
  scale_color_manual(values = c("HART" = "blue", "Linear" = "red")) +
  theme_classic(base_size = 14) +
  labs(title = "Log-Likelihood Trace Plots", x = "MCMC Iteration", y = "Log-Likelihood") +
  theme(legend.title = element_blank())
```

In-sample fit comparison after burn-in:
```{r in-sample-fit}
mean(out_hart$loglike[-c(1:burnin_draws)])
mean(out_lin$loglike[-c(1:burnin_draws)])
```

## Individual-level Coefficients

We can inspect the posterior distributions of individual-level coefficients, or part-worths. We compare the posteriors for the part-worth of the out-of-state bank attribute for two respondents. Respondent 146 is a member of a segment of older women with low income; respondent 580 is a member of a segment of middle-aged men with moderate income.

```{r individual-betas, fig.width=12, fig.height=6, fig.align='center', out.width="90%", dpi = 200, fig.cap="Posterior Distributions of Individual-level Part-Worths."}
selected_resp <- c(146, 580)
coef_indx <- 10 # "Interest" coefficient
coef_name <- colnames(bank$choiceAtt[, 3:16])[coef_indx]

# Create a combined factor for filling histograms
beta_draws <- bind_rows(
  as.data.frame(t(out_hart$betadraw[selected_resp, coef_indx, -c(1:burnin_draws)])) %>% 
    mutate(Model = "HART", Draw = row_number()),
  as.data.frame(t(out_lin$betadraw[selected_resp, coef_indx, -c(1:burnin_draws)])) %>% 
    mutate(Model = "Linear", Draw = row_number())
)
colnames(beta_draws)[1:2] <- paste("Respondent", selected_resp)

beta_draws_long <- beta_draws %>%
  pivot_longer(
    cols = starts_with("Respondent"), 
    names_to = "Respondent", 
    values_to = "Coefficient"
  ) %>% 
  mutate(
      Model = factor(Model, levels = c("Linear", "HART")), # Control facet order
      Group = interaction(Respondent, Model)
  )

# Define colors
model_fills <- c(
    "Respondent 146.Linear" = "lightcoral", "Respondent 580.Linear" = "darkred",
    "Respondent 146.HART" = "lightblue", "Respondent 580.HART" = "darkblue"
)
model_colors <- c(
    "Respondent 146.Linear" = "red", "Respondent 580.Linear" = "darkred",
    "Respondent 146.HART" = "blue", "Respondent 580.HART" = "darkblue"
)

# Calculate means
means <- beta_draws_long %>%
  group_by(Group, Model) %>%
  summarise(mean_val = mean(Coefficient), .groups = "drop")

ggplot(beta_draws_long, aes(x = Coefficient, fill = Group)) +
  geom_histogram(
    aes(y = after_stat(density)),
    alpha = 0.6, bins = 45, position = "identity", color = "black", linewidth = 0.3
  ) +
  geom_vline(
    data = means, aes(xintercept = mean_val, color = Group),
    linetype = "dashed", linewidth = 1.2
  ) +
  facet_wrap(~Model) +
  scale_fill_manual(
      name = "Respondent",
      values = model_fills,
      breaks = c("Respondent 146.Linear", "Respondent 580.Linear", "Respondent 146.HART", "Respondent 580.HART"),
      labels = c("Respondent 146", "Respondent 580", "Respondent 146", "Respondent 580")
  ) +
  scale_color_manual(values = model_colors, guide = "none") +
  theme_classic(base_size = 16) +
  theme(
    axis.title = element_text(size = 18),
    legend.position = "top",
    legend.title = element_blank(),
    strip.text = element_text(size = 16, face = "bold"),
    strip.background = element_rect(fill = "grey90", color = "black")
  ) +
    labs(
    title = paste("Posterior of", coef_name, "Coefficient"),
    x = "Coefficient Value", y = "Density"
  )
```

## The Representative Respondent

The model estimates how part-worths vary with demographics `Z`. The term `Delta(Z)` represents the expected part-worth for a "representative" respondent with characteristics `Z`. We can use the `predict` function to get the posterior draws for `Delta(Z)` for our selected respondents.

```{r predict-deltaZ, message=FALSE, warning=FALSE}
# We predict for all respondents and then select
DeltaZ_hat_hart <- predict(out_hart, newdata = Data, type = "DeltaZ+mu", burn = burn)
DeltaZ_hat_lin <- predict(out_lin, newdata = Data, type = "DeltaZ+mu", burn = burn)
```

```{r representative-respondent, fig.width=12, fig.height=6, fig.align='center', out.width="90%", dpi = 200, fig.cap="Posterior Distributions of Expected Part-Worths."}
deltaZ_draws <- bind_rows(
  as.data.frame(t(DeltaZ_hat_hart[selected_resp, coef_indx, ])) %>% 
    mutate(Model = "HART", Draw = row_number()),
  as.data.frame(t(DeltaZ_hat_lin[selected_resp, coef_indx, ])) %>% 
    mutate(Model = "Linear", Draw = row_number())
)
colnames(deltaZ_draws)[1:2] <- paste("Respondent", selected_resp)

deltaZ_draws_long <- deltaZ_draws %>%
  pivot_longer(
    cols = starts_with("Respondent"), 
    names_to = "Respondent", 
    values_to = "Coefficient"
  ) %>% 
  mutate(
      Model = factor(Model, levels = c("Linear", "HART")), # Control facet order
      Group = interaction(Respondent, Model)
  )
  
# Re-using the color definitions from the previous chunk
model_fills <- c(
    "Respondent 146.Linear" = "lightcoral", "Respondent 580.Linear" = "darkred",
    "Respondent 146.HART" = "lightblue", "Respondent 580.HART" = "darkblue"
)
model_colors <- c(
    "Respondent 146.Linear" = "red", "Respondent 580.Linear" = "darkred",
    "Respondent 146.HART" = "blue", "Respondent 580.HART" = "darkblue"
)

# Calculate means
means_deltaZ <- deltaZ_draws_long %>%
  group_by(Group, Model) %>%
  summarise(mean_val = mean(Coefficient), .groups = "drop")

ggplot(deltaZ_draws_long, aes(x = Coefficient, fill = Group)) +
  geom_histogram(
    aes(y = after_stat(density)),
    alpha = 0.6, bins = 45, position = "identity", color = "black", linewidth = 0.3
  ) +
  geom_vline(
    data = means_deltaZ, aes(xintercept = mean_val, color = Group),
    linetype = "dashed", linewidth = 1.2
  ) +
  facet_wrap(~Model) +
  scale_fill_manual(
      name = "Respondent",
      values = model_fills,
      breaks = c("Respondent 146.Linear", "Respondent 580.Linear", "Respondent 146.HART", "Respondent 580.HART"),
      labels = c("Respondent 146", "Respondent 580", "Respondent 146", "Respondent 580")
  ) +
  scale_color_manual(values = model_colors, guide = "none") +
  theme_classic(base_size = 16) +
  theme(
    axis.title = element_text(size = 18),
    legend.position = "top",
    legend.title = element_blank(),
    strip.text = element_text(size = 16, face = "bold"),
    strip.background = element_rect(fill = "grey90", color = "black")
  ) +
    labs(
    title = paste("Posterior of Representative Respondent's '", coef_name, "' Coefficient (DeltaZ+mu)"),
    x = "Coefficient Value", y = "Density"
  )
```

## References

Allenby, Greg M. and James L. Ginter (1995). “Using Extremes to Design Products and Segment Markets.” *Journal of Marketing Research* 32.4, pp. 392–403.

Wiemann, Thomas (2025). "Personalization with HART." Working paper.

    